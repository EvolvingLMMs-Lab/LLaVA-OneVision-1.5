# Docker environment configuration for LLaVA-OneVision-1.5
# Copy this file to .env and customize the paths for your environment

# =============================================================================
# Data Directories (Customize these paths to match your setup)
# =============================================================================

# Directory containing your training datasets
DATA_DIR=/path/to/your/data

# Directory containing pre-trained models and tokenizers
MODEL_DIR=/path/to/your/models

# Directory for saving training checkpoints
CHECKPOINT_DIR=/path/to/your/checkpoints

# Directory for output files (predictions, logs, etc.)
OUTPUT_DIR=/path/to/your/outputs

# Directory for configuration files
CONFIG_DIR=/path/to/your/configs

# Directory for training logs
LOG_DIR=/path/to/your/logs

# =============================================================================
# GPU Configuration
# =============================================================================

# Specify which GPUs to use (all, none, or specific GPU IDs like "0,1,2,3")
CUDA_VISIBLE_DEVICES=all

# =============================================================================
# Inference Configuration
# =============================================================================

# Port for inference server
INFERENCE_PORT=8000

# =============================================================================
# Training Configuration
# =============================================================================

# Number of GPUs per node for training
GPUS_PER_NODE=8

# Batch size configuration
GLOBAL_BATCH_SIZE=256
MICRO_BATCH_SIZE=1

# Learning rate
LEARNING_RATE=1e-4

# Training steps
MAX_STEPS=10000

# =============================================================================
# Example Configurations
# =============================================================================

# Example 1: Local development setup
# DATA_DIR=./data
# MODEL_DIR=./models
# CHECKPOINT_DIR=./checkpoints
# OUTPUT_DIR=./outputs
# CONFIG_DIR=./configs
# LOG_DIR=./logs
# CUDA_VISIBLE_DEVICES=0

# Example 2: Multi-GPU server setup
# DATA_DIR=/mnt/data/llava
# MODEL_DIR=/mnt/models/llava
# CHECKPOINT_DIR=/mnt/checkpoints/llava
# OUTPUT_DIR=/mnt/outputs/llava
# CONFIG_DIR=/mnt/configs/llava
# LOG_DIR=/mnt/logs/llava
# CUDA_VISIBLE_DEVICES=0,1,2,3

# Example 3: HPC cluster setup
# DATA_DIR=/shared/datasets/llava
# MODEL_DIR=/shared/models/llava
# CHECKPOINT_DIR=/shared/checkpoints/llava-$(date +%Y%m%d)
# OUTPUT_DIR=/shared/outputs/llava-$(date +%Y%m%d)
# CONFIG_DIR=/shared/configs/llava
# LOG_DIR=/shared/logs/llava
# CUDA_VISIBLE_DEVICES=all